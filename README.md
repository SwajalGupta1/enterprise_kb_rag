

# ğŸ¤– Multi-Source Retrieval-Augmented AI Assistant (Groq + FAISS + Streamlit)

OmniRAG is an advanced **Retrieval-Augmented Generation (RAG)** system that ingests PDFs, CSVs, text files, web URLs, or raw text and instantly builds a searchable knowledge base. It generates embeddings using **Groqâ€™s LLaMA 3.2 Embedding model**, performs semantic search with **FAISS**, and produces accurate grounded answers using **Groq LLaMA models** â€” all inside a clean, intuitive Streamlit interface.

---

## ğŸš€ Features

- Multi-source ingestion: **PDF, TXT, CSV, Website URLs, Direct Text**
- Automatic text extraction, cleaning & preprocessing
- Smart chunking with metadata tracking
- Embeddings via **Groq LLaMA 3.2 Embedding Model**
- Fast vector search using **FAISS**
- RAG-based answer generation using **Groq LLaMA 3.x models**
- Streamlit UI with:
  - ğŸ“¥ Ingestion Tab  
  - â“ Querying Tab
- Fully deployable on **Streamlit Cloud**
- No local model downloads required â€” cloud-based LLM & embeddings

---

## ğŸ§  Tech Stack

- **Python 3.13**
- **Streamlit**
- **Groq API (Embeddings + LLMs)**
- **FAISS**
- **PyPDF2**
- **BeautifulSoup4**
- **pandas / numpy**
- **dotenv / Streamlit Secrets**
- **Requests**
- **GitHub + Streamlit Cloud**

---

## ğŸ“ Project Structure



- enterprise_kb_rag/
- â”‚
- â”œâ”€â”€ app/
- â”‚ â””â”€â”€ streamlit_app.py
- â”‚
- â”œâ”€â”€ ingestion/
- â”‚ â”œâ”€â”€ loaders.py
- â”‚ â”œâ”€â”€ processors.py
- â”‚ â”œâ”€â”€ chunker.py
- â”‚ â””â”€â”€ indexer.py
- â”‚
- â”œâ”€â”€ querying/
- â”‚ â”œâ”€â”€ retriever.py
- â”‚ â””â”€â”€ generator.py
- â”‚
- â”œâ”€â”€ requirements.txt
- â””â”€â”€ README.md
---

## âš™ï¸ How OmniRAG Works

1. User uploads files or enters text/URL  
2. System extracts raw text from PDF/CSV/TXT/Web  
3. Text is cleaned, normalized, and chunked  
4. Each chunk gets embedded using **Groq Embeddings API**  
5. FAISS indexes vectors for semantic search  
6. User asks a question  
7. Query is embedded â†’ top-k chunks retrieved  
8. A structured RAG prompt is generated with sources  
9. **Groq LLaMA model** produces the final answer  

---

## Streamlit URL
https://enterprisekbrag-kyqyus86xqqtlh3jdknssz.streamlit.app/


